{"cells":[{"cell_type":"markdown","metadata":{"id":"OFOTiqrtNvyy"},"source":["# Install Transformers Library"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D3Jb2PlR4R7j","outputId":"52e1dc83-c061-43eb-b3b5-fc51e7e4126d"},"outputs":[],"source":["# !pip install transformers\n","# !pip install --upgrade transformers\n","# from transformers import __version__; print(__version__)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"x4giRzM7NtHJ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import time\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import AutoTokenizer\n","\n","# paramters\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"kKd-Tj3hOMsZ"},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"executionInfo":{"elapsed":5,"status":"error","timestamp":1684347465128,"user":{"displayName":"Saad Munir","userId":"02062958913544665151"},"user_tz":-300},"id":"cwJrQFQgN_BE","outputId":"a0aa8d02-2455-4a43-b284-d7bde8d1eab6"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X-Folder</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>california</td>\n","      <td>caiso notice summer 2001 generation rfb market...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>california</td>\n","      <td>ca iso cal px information related 2000 market ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>california</td>\n","      <td>caiso notification update inter sc trades adju...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>california</td>\n","      <td>update mif meeting presentations iso website u...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>california</td>\n","      <td>mif presentations presentations market issues ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     X-Folder                                               text\n","0  california  caiso notice summer 2001 generation rfb market...\n","1  california  ca iso cal px information related 2000 market ...\n","2  california  caiso notification update inter sc trades adju...\n","3  california  update mif meeting presentations iso website u...\n","4  california  mif presentations presentations market issues ..."]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('ML-TextClassification\\02 - Email Classification - EnronData\\dataset\\preprocessed.csv')\n","data.head()"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"fzPPOrVQWiW5"},"outputs":[{"name":"stdout","output_type":"stream","text":["(16911, 2)\n","(16911, 2)\n","X-Folder    0\n","text        0\n","dtype: int64\n"]}],"source":["print(data.shape)\n","data.dropna(inplace=True)\n","print(data.shape)\n","print(data.isnull().sum())"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"676DPU1BOPdp"},"outputs":[{"data":{"text/plain":["30"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["\n","# print unique values in the column\n","data['X-Folder'].unique()\n","# print unique values in the column and their counts in descending order\n","data['X-Folder'].value_counts()\n","# print total number of unique values in the column\n","data['X-Folder'].nunique()"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","def label_encoder(data):\n","    class_le = LabelEncoder()\n","    # apply label encoder on the 'X-Folder' column\n","    y = class_le.fit_transform(data['X-Folder'])\n","    return y\n","\n","# call label_encoder on the data\n","y = label_encoder(data)\n","x = data['text']\n"]},{"cell_type":"markdown","metadata":{"id":"MKfWnApvOoE7"},"source":["# Split train dataset into train, validation and test sets"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"mfhSPF5jOWb7"},"outputs":[],"source":["train_text, temp_text, train_labels, temp_labels = train_test_split(x, y, \n","                                                                    random_state=2018, \n","                                                                    test_size=0.7, \n","                                                                    stratify=y)\n","\n","# we will use temp_text and temp_labels to create validation and test set\n","val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n","                                                                random_state=2018, \n","                                                                test_size=0.5, \n","                                                                stratify=temp_labels)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"KRPfbWbk4Ji_"},"outputs":[{"data":{"text/plain":["7228     california update 7 16 01 executive summary so...\n","4468     eol credit responses 09 13 00 tana following c...\n","10293    pogo c lea co keep mind wait see well producer...\n","8543     fw original message kitchen louise sent tuesda...\n","6217     lsu visit resume datren forwarding resume anal...\n","                               ...                        \n","5250     revision 1st request approve attached request ...\n","13816            apb checkout 513386 apb 514418 broker cob\n","6044     interview schedule rabi de attached please fin...\n","3827     exhibit 1 feb 00 chris spreadsheet sent yester...\n","14331    5 1 checkout bloomberg chris mallory deal 5981...\n","Name: text, Length: 5073, dtype: object"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["train_text"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"0xwTnZuuCT1u"},"outputs":[{"data":{"text/plain":["7611     fw original message oquinn kari sent friday de...\n","10606    updated livelink discussion hello everyone con...\n","10989    cal 2000 historical enronearthsmartbizmix disc...\n","15634    clickpaper report 12 20 00 1 2 01 questions re...\n","13098    presentations jim two presentations old presen...\n","                               ...                        \n","551      power plants great river power tex information...\n","16804    bally total fitness offer wtc tenants us world...\n","1010     project finance week march 11 15 new york city...\n","12163    charles la bella follow yesterday e mail attac...\n","11351    revised cinergy model gents made following cha...\n","Name: text, Length: 5919, dtype: object"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["test_text"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"LUIOlct0CMFn"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.series.Series'>\n","<class 'numpy.ndarray'>\n"]}],"source":["print(type(test_text))\n","print(type(test_labels))"]},{"cell_type":"markdown","metadata":{"id":"n7hsdLoCO7uB"},"source":["# Import BERT Model and BERT Tokenizer"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"S1kY3gZjO2RE"},"outputs":[],"source":["# import multilingual BERT base pretrained model\n","# bert = AutoModel.from_pretrained('bert-base-multilingual-cased')\n","# tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n","\n","bert_base_uncased = AutoModel.from_pretrained('bert-base-uncased')\n","# Load the multilingual BERT tokenizer\n","tokenizer_base_uncased = AutoTokenizer.from_pretrained('bert-base-uncased')\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': tensor([[  101,  1045,  2467,  2203,  2039,  2746,  2067,  2000,  2023,   102],\n","        [  101,  2057,  2097,  2986,  1011,  8694,  1037, 14324,  2944,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"]}],"source":["# encode the texts\n","\n","encoded_dict = tokenizer_base_uncased.batch_encode_plus(sample_text, \n","                                            add_special_tokens=True, \n","                                            padding=True, \n","                                            truncation=True, \n","                                            max_length=10, \n","                                            return_attention_mask=True, \n","                                            return_tensors='pt')\n","# print the encoded output\n","print(encoded_dict)"]},{"cell_type":"markdown","metadata":{"id":"8wIYaWI_Prg8"},"source":["# Tokenization"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"background_save":true},"id":"yKwbpeN_PMiu","outputId":"dfe9d508-c295-495d-b320-74011a5f71af"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","seq_len = []\n","for text in train_text:\n","    if isinstance(text, str):\n","        seq_len.append(len(text.split()))\n","pd.Series(seq_len).hist(bins=30)\n","# add title and labels\n","plt.title('Enron Data')\n","plt.xlabel('Number of Words')\n","plt.ylabel('Frequency')\n","plt.show()\n"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"tk5S7DWaP2t6"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["max_seq_len = 500\n","# tokenize and encode sequences in the training set\n","tokens_train = tokenizer_base_uncased.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer_base_uncased.batch_encode_plus(\n","    val_text.tolist(),\n","    #max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer_base_uncased.batch_encode_plus(\n","    test_text.tolist(),\n","    #max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")"]},{"cell_type":"markdown","metadata":{"id":"Wsm8bkRZQTw9"},"source":["# Convert Integer Sequences to Tensors"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"QR-lXwmzQPd6"},"outputs":[],"source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for validation set\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","# for test set\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"]},{"cell_type":"markdown","metadata":{"id":"Ov1cOBlcRLuk"},"source":["# Create DataLoaders"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"qUy9JKFYQYLp"},"outputs":[],"source":["#define a batch size\n","batch_size = 32\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"K2HZc5ZYRV28"},"source":["# Freeze BERT Parameters"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"wHZ0MC00RQA_"},"outputs":[],"source":["# freeze all the parameters\n","for param in bert_base_uncased.parameters():\n","    param.requires_grad = False"]},{"cell_type":"markdown","metadata":{"id":"s7ahGBUWRi3X"},"source":["# Define Model Architecture"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"b3iEtGyYRd0A"},"outputs":[],"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert):\n","      \n","      super(BERT_Arch, self).__init__()\n","\n","      self.bert = bert \n","      \n","      # dropout layer\n","      self.dropout = nn.Dropout(0.1)\n","      \n","      # relu activation function\n","      self.relu =  nn.ReLU()\n","\n","      # dense layer 1\n","      self.fc1 = nn.Linear(768,512)\n","      \n","      # dense layer 2 (Output layer)\n","      self.fc2 = nn.Linear(512,30)\n","\n","      #softmax activation function\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","      #pass the inputs to the model  \n","      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n","      \n","      x = self.fc1(cls_hs)\n","\n","      x = self.relu(x)\n","\n","      x = self.dropout(x)\n","\n","      # output layer\n","      x = self.fc2(x)\n","      \n","      # apply softmax activation\n","      x = self.softmax(x)\n","\n","      return x"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"cBAJJVuJRliv"},"outputs":[],"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(bert_base_uncased)\n","\n","# push the model to GPU\n","model = model.to(device)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"taXS0IilRn9J"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(), lr = 1e-3)"]},{"cell_type":"markdown","metadata":{"id":"j9CDpoMQR_rK"},"source":["# Find Class Weights"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"izY5xH5eR7Ur"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.34206349 0.56179402 0.8052381  0.55625    1.81827957 0.98313953\n"," 1.7255102  1.34206349 0.64296578 0.95       1.96627907 0.84974874\n"," 1.96627907 1.21654676 1.44529915 1.58037383 1.58037383 1.03742331\n"," 1.14256757 0.48176638 0.70458333 0.99470588 1.19084507 1.22536232\n"," 1.78       0.93944444 0.93425414 0.49014493 1.56574074 1.691     ]\n"]}],"source":["from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n","\n","classes = np.unique(train_labels)\n","class_wts = compute_class_weight(class_weight='balanced', classes=classes, y=train_labels)\n","# as data is not balanced, we are using class weights to balance it out \n","\n","print(class_wts)"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"r1WvfY2vSGKi"},"outputs":[],"source":["# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","# number of training epochs\n","epochs = 250"]},{"cell_type":"markdown","metadata":{"id":"My4CA0qaShLq"},"source":["# Fine-Tune BERT"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"rskLk8R_SahS"},"outputs":[],"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    \n","    # progress update after every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # update parameters\n","    optimizer.step()\n","\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"yGXovFDlSxB5"},"outputs":[],"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    \n","    # Progress update every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","      # elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","      \n","      # model predictions\n","      preds = model(sent_id, mask)\n","\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"]},{"cell_type":"markdown","metadata":{"id":"9KZEgxRRTLXG"},"source":["# Start Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"k1USGTntS3TS","outputId":"e87393bf-343c-4bdf-d439-fa7bc9876612"},"outputs":[],"source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss, _ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'BERT_saved_weights_EnronData.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPdbxg6nS-sc"},"outputs":[],"source":["import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3OzvSsces_s_"},"outputs":[],"source":["plt.plot(range(len(train_losses)), train_losses, label='Train')\n","plt.plot(range(len(valid_losses)), valid_losses, label='Valid')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show() "]},{"cell_type":"markdown","metadata":{"id":"x4SVftkkTZXA"},"source":["# Get Predictions for Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":590,"status":"error","timestamp":1684351072442,"user":{"displayName":"Saad Munir","userId":"02062958913544665151"},"user_tz":-300},"id":"Ms1ObHZxTYSI","outputId":"cf835a80-488a-4caf-fb93-63ee8d20c5a8"},"outputs":[],"source":["\n","# pass the pre-trained BERT to our define architecture\n","test_model = BERT_Arch(bert_base_uncased)\n","test_model = test_model.to(device)\n","test_model.load_state_dict(torch.load('D:\\skyline project\\Projects\\week1\\weights\\BERT_saved_weights_EnronData.pt'))\n","\n","with torch.no_grad():\n","  pred_proba = test_model(test_seq.to(device), test_mask.to(device))\n","  pred_proba = pred_proba.detach().cpu().numpy()\n","\n","preds = np.argmax(pred_proba, axis = 1)\n","\n","print([preds.tolist(), pred_proba.tolist()])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E83oHn9g4JjP"},"outputs":[],"source":["# import libraries\n","from sklearn.metrics import (classification_report, f1_score, recall_score, precision_score, accuracy_score,log_loss,\n","                             precision_recall_curve, confusion_matrix, matthews_corrcoef)\n","print(\"Accuracy: \", accuracy_score(test_y, preds))\n","print(\"Loss: \", log_loss(test_y, pred_proba))\n","print('F1 score', f1_score(test_y, preds, average='weighted'))\n","print('Precision score', precision_score(test_y, preds, average='weighted'))\n","print('Recall score', recall_score(test_y, preds, average='weighted'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"12avO_iR4JjP"},"outputs":[],"source":["import seaborn as sns\n","# Confusion matrix\n","cm = confusion_matrix(test_y, preds)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1'], yticklabels=['0', '1'])\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Inference"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"iP__zM8HJQYu"},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[ 101, 4638, 2041, 2023, 2678, 2006, 7858, 1024, 9130,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["# lets do some predictions on the new user input text \n","# we will use the same preprocessing steps as before\n","# we will use the same tokenizer as before\n","# we will use the same model as before\n","\n","# just call the above preprocessing function on the new user input text \n","# and then pass the preprocessed text to the model for prediction\n","inference_text = [ 'Check out this video on YouTube:Facebook']\n","\n","encoded_dict = tokenizer_base_uncased.batch_encode_plus(inference_text, \n","                                            add_special_tokens=True, \n","                                            padding=True, \n","                                            truncation=True, \n","                                            max_length=10, \n","                                            return_attention_mask=True, \n","                                            return_tensors='pt')\n","encoded_dict"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22820\\1002175802.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  input_ids = torch.tensor(encoded_dict['input_ids'], dtype=torch.long)\n","C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22820\\1002175802.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  token_type_ids = torch.tensor(encoded_dict['token_type_ids'], dtype=torch.long)\n","C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22820\\1002175802.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_mask = torch.tensor(encoded_dict['attention_mask'], dtype=torch.long)\n"]}],"source":["# convert the encoded dict values input_ids, token_type_ids, attention_mask to tensors for feeding into the model\n","\n","input_ids = torch.tensor(encoded_dict['input_ids'], dtype=torch.long)\n","token_type_ids = torch.tensor(encoded_dict['token_type_ids'], dtype=torch.long)\n","attention_mask = torch.tensor(encoded_dict['attention_mask'], dtype=torch.long)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# pass the tensors to the model to get the predictions\n","\n","with torch.no_grad():\n","    outputs = test_model(input_ids, attention_mask)\n","    logits = outputs[0]\n","    # get the index of the highest prediction\n","    prediction = torch.argmax(logits).item()\n","\n","print(\"Prediction: \", prediction)\n","# match the prediction with the label in the label dictionary to get the label name \n","print(\"Label: \", label_dict[prediction])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
